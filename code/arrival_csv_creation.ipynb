{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Creating Main DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv and transformin into DataFrame\n",
    "    # flight logs DataFrame\n",
    "flights = pd.read_csv(os.getcwd() + r'\\\\main_related_archives\\\\flight_logs.csv')\n",
    "\n",
    "    # METAR logs DataFrame\n",
    "metar = pd.read_csv(os.getcwd() + r'\\\\main_related_archives\\\\metar_logs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Section 1.1 - Adjustment of 'expected_arrival' for alignment with METAR records\n",
    "\n",
    " For proper integration of the dataframes, it's crucial to round the 'expected_arrival' times to the nearest hour (setting minutes and seconds to 00). This step ensures that the 'expected_arrival' times are synchronized with the hourly time windows of METAR logs. By doing this, we ensure consistent correlation of flight data with recorded meteorological conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting column to datetime\n",
    "# Primeiro, converta a coluna para o formato datetime\n",
    "flights['expected_arrival'] = pd.to_datetime(flights['expected_arrival'])\n",
    "\n",
    "# nect, trunc time to most near time\n",
    "flights['expected_arrival'] = flights['expected_arrival'].dt.floor('h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 - filtering by SBGR origin and selectin just used columns\n",
    "- \"destiny\"\n",
    "- \"expected_arrival\"\n",
    "- \"arrival_status\"\n",
    "- \"arrival_delay_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by 'origin' = 'SBGR' (sbgr origin departures)\n",
    "arrivals = flights[flights['destiny'] == 'SBGR']\n",
    "\n",
    "# Only required columns\n",
    "arrivals = arrivals[['destiny', 'expected_arrival', 'arrival_status', 'arrival_delay_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Join with metar logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking collumns datetime format\n",
    "arrivals['expected_arrival'] = pd.to_datetime(arrivals['expected_arrival'])\n",
    "metar['date_time'] = pd.to_datetime(metar['date_time'])\n",
    "\n",
    "# Left Join\n",
    "arrival = pd.merge(arrivals, metar, left_on='expected_arrival', right_on='date_time', how='left')\n",
    "\n",
    "#drop not used columns\n",
    "arrival = arrival.drop(columns=['destiny', 'date_time', 'station_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 Juntando chuvas em um dado só"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining values ​​that indicate rain\n",
    "weather_conditions = ['TS', '-TSRA', '+TSRA', 'TSRA']\n",
    "\n",
    "# creating new column for rain 'RA' (boolean)\n",
    "arrival['ts'] = arrival['current_wx1'].isin(weather_conditions).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dataframe to csv and saves on main_related_archives folder\n",
    "\n",
    "#getting path folder\n",
    "path = os.getcwd() + '/main_related_archives'\n",
    "\n",
    "#saving csv\n",
    "arrival.to_csv(path + '/arrival_logs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Coping to RProject folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get actual dir\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# get father dir\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# dir r_analysis (R Project dir)\n",
    "r_path = parent_dir + '/r_analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Data Scientist\\\\MBA\\\\TCC\\\\repo\\\\weather-delay-investigation-MBA-/r_analysis/arrival_logs.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Copyng original file to r_project dir\n",
    "\n",
    "# original path file (plus archive name)\n",
    "original_csv = path + '/arrival_logs.csv'\n",
    "\n",
    "# r_project file path to save (plus archiuve name)\n",
    "copy_path = r_path + '/arrival_logs.csv'\n",
    "\n",
    "# Copiando o arquivo\n",
    "shutil.copy2(original_csv, copy_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
